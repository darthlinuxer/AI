{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f60e72f9",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "A type of AI language model architecture that combines the strengths of traditional transformer-based language models with the strengths of retrieval-based approaches.\n",
    "\n",
    "## 1st step: **Indexing**\n",
    "1. Load: First we need to load our data. This is done with DocumentLoaders.\n",
    "2. Split: Text splitters break large Documents into smaller chunks. This is useful both for indexing data and for passing it in to a model, since large chunks are harder to search over and won’t fit in a model’s finite context window.\n",
    "3. Store: We need somewhere to store and index our splits, so that they can later be searched over. This is often done using a VectorStore and Embeddings model.\n",
    "\n",
    "![Rag Architecture](../Resources/RAG_image1.png)\n",
    "\n",
    "## 2nd Step: **Query**\n",
    "\n",
    "![Rag Query](../Resources/RAG_image2.png)\n",
    "\n",
    "## Traditional Generation vs RAG\n",
    "\n",
    "**Traditional Generation**\n",
    "\n",
    "* Generates text entirely from scratch\n",
    "* Uses learnable parameters and mathematical operations\n",
    "* Can be effective for generating coherent and fluent text, but may not always produce highly relevant or accurate results\n",
    "\n",
    "**Retrieval-Augmented Generation (RAG)**\n",
    "\n",
    "* Augments traditional generation with a retrieval step\n",
    "* Retrieves relevant pieces of text from a large database\n",
    "* Combines retrieved text with generation to inform the text generation process\n",
    "\n",
    "## Benefits of RAG\n",
    "\n",
    "* Benefits from the coherence and fluency of traditional generation-based models\n",
    "* Leverages the accuracy and relevance of retrieval-based approaches\n",
    "* Generates more accurate and informative text by incorporating external knowledge\n",
    "\n",
    "## Applications of RAG\n",
    "\n",
    "* Text summarization\n",
    "* Question answering\n",
    "* Conversation generation\n",
    "* Chatbots\n",
    "* Content creation\n",
    "* Language translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae7f0b67",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "module ''langchain_core._api'.'deprecation'' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunnablePassthrough\n",
      "File \u001b[0;32m~/AI/venv/lib/python3.12/site-packages/langchain_openai/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     AzureChatOpenAI,\n\u001b[1;32m      3\u001b[0m     ChatOpenAI,\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m     AzureOpenAIEmbeddings,\n\u001b[1;32m      7\u001b[0m     OpenAIEmbeddings,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAI, OpenAI\n",
      "File \u001b[0;32m~/AI/venv/lib/python3.12/site-packages/langchain_openai/chat_models/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mazure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[1;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAzureChatOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m ]\n",
      "File \u001b[0;32m~/AI/venv/lib/python3.12/site-packages/langchain_openai/chat_models/azure.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Dict, List, Optional, Union\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatResult\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic_v1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Field, SecretStr, root_validator\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_to_secret_str, get_from_dict_or_env\n",
      "File \u001b[0;32m~/AI/venv/lib/python3.12/site-packages/langchain_core/__init__.py:11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"``langchain-core`` defines the base abstractions for the LangChain ecosystem.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThe interfaces for core components like chat models, LLMs, vector stores, retrievers,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03mvery lightweight.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     12\u001b[0m     surface_langchain_beta_warnings,\n\u001b[1;32m     13\u001b[0m     surface_langchain_deprecation_warnings,\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VERSION\n\u001b[1;32m     17\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m VERSION\n",
      "File \u001b[0;32m~/AI/venv/lib/python3.12/site-packages/langchain_core/_api/__init__.py:63\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(attr_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m     62\u001b[0m     module_name \u001b[38;5;241m=\u001b[39m _dynamic_imports\u001b[38;5;241m.\u001b[39mget(attr_name)\n\u001b[0;32m---> 63\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mimport_attr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__spec__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mglobals\u001b[39m()[attr_name] \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/AI/venv/lib/python3.12/site-packages/langchain_core/_import_utils.py:32\u001b[0m, in \u001b[0;36mimport_attr\u001b[0;34m(attr_name, module_name, package)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 32\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, attr_name)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mImportError\u001b[0m: module ''langchain_core._api'.'deprecation'' not found"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import Any\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "\n",
    "retriever: Any = None\n",
    "\n",
    "def create_in_memory_retriever(chunks:list):\n",
    "    embed_function = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "    # Create a FAISS vector store from the document chunks\n",
    "    vectorstore = FAISS.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embed_function\n",
    "    )\n",
    "    if retriever is not None:\n",
    "        print(\"A retriever already exists\")\n",
    "        return retriever\n",
    "    global retriever\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "def rag(question:str, retriever: Any):\n",
    "    local_llm = ChatOpenAI(name=\"gpt-3.5-turbo\")\n",
    "    prompt_template=\"\"\"Answer the question based only on the following context:\n",
    "    ==============================\n",
    "    {context}\n",
    "    ==============================\n",
    "    Question: {question}\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "    chain = (\n",
    "        # You need a RunnablePassThrough if you are going to pass the parameter to the chain\n",
    "        {\n",
    "            \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
    "            \"question\": RunnablePassthrough(),\n",
    "            \"result\": (\n",
    "                lambda x: print(f\"Question: {x['question']}\\nContext: {x['context']}\"),\n",
    "                StrOutputParser(),\n",
    "                local_llm,\n",
    "                prompt\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    print(f\"Question: {question}\\nContext: {result['context']}\")\n",
    "    return result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21f9647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "text = \"\"\"\n",
    "The astronauts on the International Space Station conducted a spacewalk to repair a malfunctioning solar panel. \n",
    "The aroma of freshly baked croissants wafted through the charming French bakery. \n",
    "The new policy aimed to reduce carbon emissions by 50% within the next decade. \n",
    "The ancient Egyptian pharaohs were known for their elaborate headdresses and ornate jewelry.\"\"\"\n",
    "\n",
    "# Manual Splitting\n",
    "chunks = []\n",
    "chunk_size = 35 # Characters\n",
    "for i in range(0, len(text), chunk_size):\n",
    "    chunk = text[i:i + chunk_size]\n",
    "    chunks.append(chunk)\n",
    "documents = [Document(page_content=chunk, metadata={\"source\": \"local\"}) for chunk in chunks]\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1fe9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adee94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag(\"What the astrounauts did ?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
